#!/usr/bin/env python3
"""
AIæ¨¡å‹ä¿®å¤éªŒè¯æµ‹è¯•è„šæœ¬
ç”¨äºæµ‹è¯•ä¿®å¤åçš„AIå“åº”è§£æåŠŸèƒ½
"""

import asyncio
import aiohttp
import json
import logging
from datetime import datetime
from app import NightscoutWebMonitor

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class AIResponseTester:
    def __init__(self):
        self.monitor = NightscoutWebMonitor()
        
    def test_response_parsing(self):
        """æµ‹è¯•å“åº”è§£æåŠŸèƒ½"""
        logger.info("æµ‹è¯•AIå“åº”è§£æåŠŸèƒ½...")
        
        # æµ‹è¯•å„ç§å“åº”æ ¼å¼
        test_cases = [
            {
                "name": "OpenAIæ ‡å‡†æ ¼å¼",
                "response": {
                    "choices": [
                        {
                            "message": {
                                "content": "è¿™æ˜¯OpenAIæ ‡å‡†æ ¼å¼çš„å“åº”"
                            }
                        }
                    ]
                },
                "expected": "è¿™æ˜¯OpenAIæ ‡å‡†æ ¼å¼çš„å“åº”"
            },
            {
                "name": "ç›´æ¥contentæ ¼å¼",
                "response": {
                    "content": "è¿™æ˜¯ç›´æ¥contentæ ¼å¼çš„å“åº”"
                },
                "expected": "è¿™æ˜¯ç›´æ¥contentæ ¼å¼çš„å“åº”"
            },
            {
                "name": "Geminiæ ¼å¼",
                "response": {
                    "candidates": [
                        {
                            "content": {
                                "parts": [
                                    {
                                        "text": "è¿™æ˜¯Geminiæ ¼å¼çš„å“åº”"
                                    }
                                ]
                            }
                        }
                    ]
                },
                "expected": "è¿™æ˜¯Geminiæ ¼å¼çš„å“åº”"
            },
            {
                "name": "GLMæ•°æ®åŒ…è£…æ ¼å¼",
                "response": {
                    "data": {
                        "choices": [
                            {
                                "content": "è¿™æ˜¯GLMæ•°æ®åŒ…è£…æ ¼å¼çš„å“åº”"
                            }
                        ]
                    }
                },
                "expected": "è¿™æ˜¯GLMæ•°æ®åŒ…è£…æ ¼å¼çš„å“åº”"
            },
            {
                "name": "ç›´æ¥textæ ¼å¼",
                "response": {
                    "text": "è¿™æ˜¯ç›´æ¥textæ ¼å¼çš„å“åº”"
                },
                "expected": "è¿™æ˜¯ç›´æ¥textæ ¼å¼çš„å“åº”"
            },
            {
                "name": "responseæ ¼å¼",
                "response": {
                    "response": "è¿™æ˜¯responseæ ¼å¼çš„å“åº”"
                },
                "expected": "è¿™æ˜¯responseæ ¼å¼çš„å“åº”"
            },
            {
                "name": "answeræ ¼å¼",
                "response": {
                    "answer": "è¿™æ˜¯answeræ ¼å¼çš„å“åº”"
                },
                "expected": "è¿™æ˜¯answeræ ¼å¼çš„å“åº”"
            },
            {
                "name": "choices.textæ ¼å¼",
                "response": {
                    "choices": [
                        {
                            "text": "è¿™æ˜¯choices.textæ ¼å¼çš„å“åº”"
                        }
                    ]
                },
                "expected": "è¿™æ˜¯choices.textæ ¼å¼çš„å“åº”"
            },
            {
                "name": "choices.contentæ ¼å¼",
                "response": {
                    "choices": [
                        {
                            "content": "è¿™æ˜¯choices.contentæ ¼å¼çš„å“åº”"
                        }
                    ]
                },
                "expected": "è¿™æ˜¯choices.contentæ ¼å¼çš„å“åº”"
            },
            {
                "name": "æ— æ•ˆæ ¼å¼",
                "response": {
                    "invalid": "è¿™æ˜¯æ— æ•ˆæ ¼å¼çš„å“åº”"
                },
                "expected": None
            },
            {
                "name": "ç©ºå“åº”",
                "response": {},
                "expected": None
            }
        ]
        
        success_count = 0
        total_count = len(test_cases)
        
        for i, test_case in enumerate(test_cases, 1):
            logger.info(f"æµ‹è¯•ç”¨ä¾‹ {i}: {test_case['name']}")
            
            try:
                result = self.monitor.parse_ai_response(test_case['response'])
                
                if result == test_case['expected']:
                    logger.info(f"âœ… {test_case['name']}: è§£ææˆåŠŸ")
                    success_count += 1
                else:
                    logger.error(f"âŒ {test_case['name']}: è§£æå¤±è´¥")
                    logger.error(f"   æœŸæœ›: {test_case['expected']}")
                    logger.error(f"   å®é™…: {result}")
                    
            except Exception as e:
                logger.error(f"âŒ {test_case['name']}: è§£æå¼‚å¸¸ - {e}")
        
        logger.info(f"\nè§£æåŠŸèƒ½æµ‹è¯•ç»“æœ: {success_count}/{total_count} é€šè¿‡")
        return success_count == total_count

    def test_config_validation(self):
        """æµ‹è¯•é…ç½®éªŒè¯åŠŸèƒ½"""
        logger.info("æµ‹è¯•AIé…ç½®éªŒè¯åŠŸèƒ½...")
        
        # æµ‹è¯•å„ç§é…ç½®
        test_configs = [
            {
                "name": "å®Œæ•´é…ç½®",
                "config": {
                    "ai_config": {
                        "api_url": "https://api.openai.com/v1/chat/completions",
                        "model_name": "gpt-3.5-turbo",
                        "api_key": "test-key",
                        "timeout": 60
                    }
                },
                "should_be_valid": True
            },
            {
                "name": "ç¼ºå°‘API URL",
                "config": {
                    "ai_config": {
                        "model_name": "gpt-3.5-turbo",
                        "api_key": "test-key"
                    }
                },
                "should_be_valid": False
            },
            {
                "name": "ç¼ºå°‘æ¨¡å‹åç§°",
                "config": {
                    "ai_config": {
                        "api_url": "https://api.openai.com/v1/chat/completions",
                        "api_key": "test-key"
                    }
                },
                "should_be_valid": False
            },
            {
                "name": "æ— æ•ˆURLæ ¼å¼",
                "config": {
                    "ai_config": {
                        "api_url": "invalid-url",
                        "model_name": "gpt-3.5-turbo"
                    }
                },
                "should_be_valid": False
            },
            {
                "name": "GLMæ¨¡å‹é…ç½®",
                "config": {
                    "ai_config": {
                        "api_url": "https://open.bigmodel.cn/api/paas/v4/chat/completions",
                        "model_name": "glm-4",
                        "api_key": "test-key"
                    }
                },
                "should_be_valid": True
            },
            {
                "name": "Geminiæ¨¡å‹é…ç½®",
                "config": {
                    "ai_config": {
                        "api_url": "https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent",
                        "model_name": "gemini-pro",
                        "api_key": "test-key"
                    }
                },
                "should_be_valid": True
            },
            {
                "name": "æœ¬åœ°é…ç½®",
                "config": {
                    "ai_config": {
                        "api_url": "http://localhost:11434/v1/chat/completions",
                        "model_name": "llama3.1:8b"
                    }
                },
                "should_be_valid": True
            }
        ]
        
        success_count = 0
        total_count = len(test_configs)
        
        # ä¸´æ—¶æ›¿æ¢é…ç½®è¿›è¡Œæµ‹è¯•
        original_config = self.monitor.config
        
        for i, test_case in enumerate(test_configs, 1):
            logger.info(f"æµ‹è¯•é…ç½® {i}: {test_case['name']}")
            
            try:
                self.monitor.config = test_case['config']
                validation = self.monitor.validate_ai_config()
                
                if validation['valid'] == test_case['should_be_valid']:
                    logger.info(f"âœ… {test_case['name']}: éªŒè¯é€šè¿‡")
                    if validation['warnings']:
                        logger.info(f"   è­¦å‘Š: {validation['warnings']}")
                    success_count += 1
                else:
                    logger.error(f"âŒ {test_case['name']}: éªŒè¯å¤±è´¥")
                    logger.error(f"   æœŸæœ›æœ‰æ•ˆ: {test_case['should_be_valid']}")
                    logger.error(f"   å®é™…æœ‰æ•ˆ: {validation['valid']}")
                    if validation['errors']:
                        logger.error(f"   é”™è¯¯: {validation['errors']}")
                        
            except Exception as e:
                logger.error(f"âŒ {test_case['name']}: éªŒè¯å¼‚å¸¸ - {e}")
        
        # æ¢å¤åŸå§‹é…ç½®
        self.monitor.config = original_config
        
        logger.info(f"\né…ç½®éªŒè¯æµ‹è¯•ç»“æœ: {success_count}/{total_count} é€šè¿‡")
        return success_count == total_count

    async def test_ai_connection_simulation(self):
        """æ¨¡æ‹Ÿæµ‹è¯•AIè¿æ¥åŠŸèƒ½"""
        logger.info("æµ‹è¯•AIè¿æ¥åŠŸèƒ½ï¼ˆæ¨¡æ‹Ÿï¼‰...")
        
        # æµ‹è¯•é…ç½®éªŒè¯
        validation = self.monitor.validate_ai_config()
        
        if not validation['valid']:
            logger.error("é…ç½®éªŒè¯å¤±è´¥ï¼Œè·³è¿‡è¿æ¥æµ‹è¯•")
            return False
        
        logger.info("é…ç½®éªŒè¯é€šè¿‡")
        if validation['warnings']:
            logger.info(f"é…ç½®è­¦å‘Š: {validation['warnings']}")
        
        # æ³¨æ„ï¼šè¿™é‡Œä¸è¿›è¡Œå®é™…çš„è¿æ¥æµ‹è¯•ï¼Œå› ä¸ºå¯èƒ½éœ€è¦çœŸå®çš„APIå¯†é’¥
        # ç”¨æˆ·å¯ä»¥ä½¿ç”¨ /api/test-ai ç«¯ç‚¹è¿›è¡Œå®é™…æµ‹è¯•
        logger.info("è¿æ¥æµ‹è¯•åŠŸèƒ½å·²å°±ç»ªï¼Œä½¿ç”¨ /api/test-ai ç«¯ç‚¹è¿›è¡Œå®é™…æµ‹è¯•")
        
        return True

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("å¼€å§‹æµ‹è¯•AIå“åº”ä¿®å¤æ•ˆæœ...")
    
    tester = AIResponseTester()
    
    # æµ‹è¯•å“åº”è§£æåŠŸèƒ½
    parsing_success = tester.test_response_parsing()
    
    # æµ‹è¯•é…ç½®éªŒè¯åŠŸèƒ½
    config_success = tester.test_config_validation()
    
    # æµ‹è¯•è¿æ¥åŠŸèƒ½ï¼ˆæ¨¡æ‹Ÿï¼‰
    connection_success = asyncio.run(tester.test_ai_connection_simulation())
    
    # è¾“å‡ºæ€»ä½“ç»“æœ
    logger.info(f"\n{'='*60}")
    logger.info("æµ‹è¯•ç»“æœæ±‡æ€»")
    logger.info(f"{'='*60}")
    logger.info(f"å“åº”è§£æåŠŸèƒ½: {'âœ… é€šè¿‡' if parsing_success else 'âŒ å¤±è´¥'}")
    logger.info(f"é…ç½®éªŒè¯åŠŸèƒ½: {'âœ… é€šè¿‡' if config_success else 'âŒ å¤±è´¥'}")
    logger.info(f"è¿æ¥æµ‹è¯•åŠŸèƒ½: {'âœ… é€šè¿‡' if connection_success else 'âŒ å¤±è´¥'}")
    
    overall_success = parsing_success and config_success and connection_success
    logger.info(f"\næ€»ä½“æµ‹è¯•ç»“æœ: {'âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡' if overall_success else 'âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥'}")
    
    if overall_success:
        logger.info("\nğŸ‰ ä¿®å¤éªŒè¯æˆåŠŸï¼")
        logger.info("GLM4.5å’ŒGeminiæ¨¡å‹ç°åœ¨åº”è¯¥èƒ½å¤Ÿæ­£å¸¸è¿”å›å“åº”")
        logger.info("å»ºè®®æ­¥éª¤:")
        logger.info("1. é‡å¯åº”ç”¨ä»¥å¯ç”¨æ–°çš„è§£æé€»è¾‘")
        logger.info("2. ä½¿ç”¨ /api/test-ai ç«¯ç‚¹æµ‹è¯•AIè¿æ¥")
        logger.info("3. åœ¨é…ç½®é¡µé¢ä¸­éªŒè¯AIè®¾ç½®")
        logger.info("4. å°è¯•ä½¿ç”¨AIåˆ†æå’Œå’¨è¯¢åŠŸèƒ½")
    else:
        logger.info("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¿®å¤ä»£ç ")
    
    return overall_success

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)